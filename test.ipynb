{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/mask_rcnn_barcode.h5\"\n",
    "test_image = \"test_images/20190806112122_0074_receiptNo5241_imgRect.png\"\n",
    "MODEL_DIR = \"logs\"\n",
    "def apply_mask(image, mask):\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,255,0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarcodeConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"barcode\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + balloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           barcode\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(BarcodeConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] making predictions with Mask R-CNN...\n",
      "Processing 1 images\n",
      "image                    shape: (625, 512, 3)         min:   53.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    }
   ],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import colorsys\n",
    "image = cv2.imread(test_image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = imutils.resize(image, width=512)\n",
    " \n",
    "# perform a forward pass of the network to obtain the results\n",
    "print(\"[INFO] making predictions with Mask R-CNN...\")\n",
    "r = model.detect([image], verbose=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-55.08059310913086\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = [\"BG\",'barcode']\n",
    "rects = []\n",
    "hsv = [(i / len(CLASS_NAMES), 1, 1.0) for i in range(len(CLASS_NAMES))]\n",
    "COLORS = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "for i in range(0, r[\"rois\"].shape[0]):\n",
    "    # extract the class ID and mask for the current detection, then\n",
    "    # grab the color to visualize the mask (in BGR format)\n",
    "    classID = r[\"class_ids\"][i]\n",
    "    mask = r[\"masks\"][:, :, i]\n",
    "    color = COLORS[classID][::-1]\n",
    " \n",
    "    # visualize the pixel-wise mask of the object\n",
    "    image = apply_mask(image, mask)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "origin = cv2.imread(test_image)\n",
    "origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n",
    "origin = imutils.resize(origin, width=512)\n",
    "cnts, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for cnt in cnts:\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    rects.append(rect)\n",
    "    print(rect[-1])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(origin,[box],0,(0,0,255),2)\n",
    "cv2.imshow(\"test\", origin)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99848914]\n"
     ]
    }
   ],
   "source": [
    "origin = cv2.imread(test_image)\n",
    "origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n",
    "origin = imutils.resize(origin, width=512)\n",
    "image = cv2.cvtColor(origin, cv2.COLOR_RGB2BGR)\n",
    "import imutils\n",
    "print(r[\"scores\"])\n",
    "# loop over the predicted scores and class labels\n",
    "for i in range(0, len(r[\"scores\"])):\n",
    "    # extract the bounding box information, class ID, label, predicted\n",
    "    # probability, and visualization color\n",
    "    (startY, startX, endY, endX) = r[\"rois\"][i]\n",
    "    classID = r[\"class_ids\"][i]\n",
    "    label = CLASS_NAMES[classID]\n",
    "    score = r[\"scores\"][i]\n",
    "    color = [int(c) for c in np.array(COLORS[classID]) * 255]\n",
    "    img = image[startY:endY, startX:endX]\n",
    "    rect = rects[i]\n",
    "\n",
    "    center, size, angle = rect[0], rect[1], rect[2]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    " \n",
    "    else:\n",
    "        angle = -angle\n",
    "    center, size = tuple(map(int, center)), tuple(map(int, size))\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    # calculate the rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "    # rotate the original image\n",
    "    img_rot = cv2.warpAffine(img, M, (width, height))\n",
    "\n",
    "#     draw the bounding box, class label, and score of the object\n",
    "#     cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
    "#     text = \"{}: {:.3f}\".format(label, score)\n",
    "#     y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "#     cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX,0.6, color, 2)\n",
    "    cv2.imshow(\"origin\", img)\n",
    "    cv2.imshow(\"output\", img_rot)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_path = glob.glob(\"/Users/apple/Desktop/machine_learning/projects/barcode_segment/dataset/Lv.3/*\")\n",
    "output = \"crop/Lv3\"\n",
    "import os\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(path, padding = 0):\n",
    "    \n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = imutils.resize(image, width=512)\n",
    "    r = model.detect([image], verbose=1)[0]\n",
    "    basename = os.path.basename(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    for i in range(0, len(r['scores'])):\n",
    "        (startY, startX, endY, endX) = r[\"rois\"][i]\n",
    "        img = image[startY - padding: endY + padding, startX - padding: endX+padding]\n",
    "        cv2.imwrite(os.path.join(output, \"{}.png_{}.png\".format(basename, i+1)), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in image_path:\n",
    "    crop(path, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
